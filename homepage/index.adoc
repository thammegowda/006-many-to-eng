include::header.adoc[]

:doctype: article
:encoding: utf-8
:lang: en
:toclevels: 3
//:sectnums: false
// :sectnumlevels: 4
:data-uri:
:hide-uri-scheme:
:toc: left
//injects google analytics to <head>
:docinfo2:
:source-highlighter: highlight.js
:description: RTG Many-to-English Translation Demo
:keywords: RTG, Translation, Machine Translation, NLP Demo, Low Resource Languages

==  Many-to-English Translation : RTG Demo

https://www.ibidemgroup.com/edu/traduccion-machine-translation-datos-modelos/[_Read this in Spanish |Lee esto en EspaÃ±ol_^]

There are more than 7000 languages in the world, but most translation research efforts have targeted a few high resource languages.
We create a multilingual NMT model capable of translating from 500 source languages to English.
We make this multilingual model readily downloadable and usable as a service, or as a parent model for transfer-learning to even lower-resource languages.

== Links

* Demos: [big red yellow-background]*V1: link:v1/[500â†’EnglishðŸ”¥^]* | [big red yellow-background]*V2: link:v1/[600â†’EnglishðŸ”¥^]*
* link:data-v1.html[V1 Dataset^] | link:data-v2.html[V2 Dataset^]
* link:models/[Download models^]
* Get paper: https://aclanthology.org/2021.acl-demo.37/ link:https://aclanthology.org/2021.acl-demo.37.pdf[Get PDF]
* Tools:
** MTData: https://github.com/thammegowda/mtdata/ +
   `pip install mtdata`
** NLCodec: https://isi-nlp.github.io/nlcodec/ +
   `pip install nlcodec`
** RTG: https://isi-nlp.github.io/rtg/ +
    `pip install rtg`
* Scripts, tables, and charts
    ** v1: https://github.com/thammegowda/006-many-to-eng
    ** v2: https://github.com/thammegowda/016-many-eng-v2

== Using Pretrained Models

=== Option 1: Using Docker
Step 1. Download image and run.
[source, bash]
----
# Select the model version tag https://hub.docker.com/repository/docker/tgowda/rtg-model
IMAGE=tgowda/rtg-model:500toEng-v1       # v1 model, 500-Eng translation, amd64 arch
IMAGE=tgowda/rtg-model:600toEng-v2.0      # v2, 600-Eng
IMAGE=tgowda/rtg-model:600toEng-v2.0-arm64 # v2 for arm64/aarch64 such as Apple Silicon (M1*)

# To run without using GPU; requires about 5 to 6GB CPU RAM
docker run --rm -i -p 6060:6060 $IMAGE

# Recommended: use GPU (e.g. device=0)
docker run --gpus '"device=0"' --rm -i -p 6060:6060 $IMAGE
----
//This docker image has everything -- Pytorch and rtg libs as well as model -- required to run a translation service locally.
WARNING: Docker manager may have memory and CPU core constrain enforced on your host. The above image should be permitted to use at least 6GB RAM. To adjust the RAM and CPU cores for docker image, refer to the instructions on web; e.g. https://stackoverflow.com/a/50770267/1506477

When the docker image runs successfully, you may access the translation service at `http://localhost:6060/`. No data would be shared with any cloud services.

=== Option 2: Without using Docker

**Step 1:** Setup a `conda` environment and install `rtg` library. +
If conda is missing in your system, link:https://docs.conda.io/en/latest/miniconda.html[please install miniconda^] to get started.
[source, bash]
----

conda create -n rtg python=3.7
conda activate rtg

pip install rtg==0.5.0  # for v1 model
# or
pip install rtg==0.7    # for v2 models

conda install -c conda-forge uwsgi  # needed to deploy service
----

**Step 2:** Download a model and run

[source, bash]
----
# Pick the latest version

MODEL=rtg500eng-tfm9L6L768d-bsz720k-stp200k-ens05.tgz # v1
MODEL=many-eng-v2.0-rtg600eng1024d_ful74k.tgz # # v2.0
# MODEL=many-eng-v2.1-rtg600eng1024d_ful38k_ftclip1Maug35k.tgz  # v2.1 code switching support

# Download
wget http://rtg.isi.edu/many-eng/models/$MODEL
# Extract
tar xvf $MODEL
# Use uWSGI to run it
uwsgi --http 127.0.0.1:6060 --module rtg.serve.app:app --pyargv "/path/to/extracted/dir"
# Alternatively, without uWSGI for quick testing; (not recommended)
# rtg-serve /path/to/extracted/dir
# Also, see "rtg-serve -h" to learn optional arguments for --pyargv "<here>" of uWSGI
----

=== Interaction with REST API
* Web Interface: a simple web interface is made at http://localhost:6060.
* REST API is available at http://localhost:6060/translate. +
An example interaction with REST API:
[source, bash]
----
API=http://localhost:6060/translate
curl $API --data "source=Comment allez-vous?" \
   --data "source=Bonne journÃ©e"

# API also accepts input as JSON data
curl -X POST -H "Content-Type: application/json" $API\
  --data '{"source":["Comment allez-vous?", "Bonne journÃ©e"]}'
----
NOTE: To learn more about RTG service and how to interact with it, go to link:https://isi-nlp.github.io/rtg/#_rtg_serve[RTG Docs^]

=== Decoding in Batch Mode
[source, bash]
----
# `pip install rtg==0.5.0` should have already installed sacremoses-xt
pip install sacremoses-xt==0.0.44
sacremoses normalize -q -d -p -c tokenize -a -x -p :web: < input.src > input.src.tok

CUDA_VISIBLE_DEVICES=0   # set GPU device ID
rtg-decode /path/to/model-extract -if input.src.tok -of output.out

# post process; drop <unk>s, detokenize
cut -f1 output.out | sed 's/<unk>//g' | sacremoses detokenize > output.out.detok
----

[#transferlearn]
== Parent-Child Transfer for Low Resource MT
Refer to the documentation at link:https://isi-nlp.github.io/rtg/#conf-parent-child[RTG Docs^]

Learning rate parameter of child model trainer is a crucial parameter: higher learning rate would destroy parent model's weights, and lower learning rate means less adaptation to child dataset.
Hence, learning rate has to be just right; refer to `conf.yml` files in https://github.com/thammegowda/006-many-to-eng/tree/master/lowres-xfer


== Citation
Please use the following article to reference this work:

https://aclanthology.org/2021.acl-demo.37/

[souce,bib]
----
@inproceedings{gowda-etal-2021-many,
    title = "Many-to-{E}nglish Machine Translation Tools, Data, and Pretrained Models",
    author = "Gowda, Thamme  and
      Zhang, Zhao  and
      Mattmann, Chris  and
      May, Jonathan",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-demo.37",
    doi = "10.18653/v1/2021.acl-demo.37",
    pages = "306--316",
}
----

== Acknowledgments

* The research is based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via AFRL Contract #FA8650-17-C-9116. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.
* This material is based on research sponsored by Air Force Research Laboratory (AFRL) under agreement number FA8750-19-1-1000. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation therein.
