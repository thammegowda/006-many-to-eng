{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download datasets\n",
    "\n",
    "`get_data.sh` prints commands that can download datasets and `parallel -j <n>` is used to parallelize downloads \n",
    "\n",
    "All the datasets are saved under `datasets` directory.\n",
    "\n",
    "`datasets/<lang>-eng/mtdata.signature.txt` file flags as a succesful download. Delete these files to re-download.\n",
    "\n",
    "Note: this is disk and network intensive task, so dont use too many parallel jobs ; 20 is a good limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "./get_data.sh  | parallel -j 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: q: command not found\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "stats=dataset-stats.tsv \n",
    "[[ -f $stats ]] || {\n",
    "    (printf \"Lang\\tSents\\tXXX\\tENG\\tHeldout\\n\"\n",
    "    for i in datasets/*; do\n",
    "        lang=$(echo $i | cut -f2 -d/ | cut -f1 -d-)  # datasets/spa-eng -> spa\n",
    "        stat1=$(wc -lw < $i/train.$lang | awk -v OFS='\\t' '{print $1,$2}')\n",
    "        stat2=$(wc -w < $i/train.eng)\n",
    "        heldout=$(ls $i/tests/*.eng 2> /dev/null | wc -l )\n",
    "        printf \"$lang\\t$stat1\\t$stat2\\t$heldout\\n\"\n",
    "    done\n",
    "    ) > $stats\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lang</th>\n",
       "      <th>Sents</th>\n",
       "      <th>XXX</th>\n",
       "      <th>ENG</th>\n",
       "      <th>Heldout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abk</td>\n",
       "      <td>24699</td>\n",
       "      <td>307650</td>\n",
       "      <td>439727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ace</td>\n",
       "      <td>1021</td>\n",
       "      <td>12026</td>\n",
       "      <td>12200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ach</td>\n",
       "      <td>78958</td>\n",
       "      <td>1544241</td>\n",
       "      <td>1359292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acm</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acu</td>\n",
       "      <td>12953</td>\n",
       "      <td>292220</td>\n",
       "      <td>290637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>zpa</td>\n",
       "      <td>365</td>\n",
       "      <td>6381</td>\n",
       "      <td>6642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>zsl</td>\n",
       "      <td>2299</td>\n",
       "      <td>37803</td>\n",
       "      <td>37420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>zsm</td>\n",
       "      <td>1234</td>\n",
       "      <td>7898</td>\n",
       "      <td>8674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>zul</td>\n",
       "      <td>1066419</td>\n",
       "      <td>14324960</td>\n",
       "      <td>19162983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>zza</td>\n",
       "      <td>522</td>\n",
       "      <td>2384</td>\n",
       "      <td>2520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lang    Sents       XXX       ENG  Heldout\n",
       "0    abk    24699    307650    439727        0\n",
       "1    ace     1021     12026     12200        0\n",
       "2    ach    78958   1544241   1359292        0\n",
       "3    acm       11        52        75        0\n",
       "4    acu    12953    292220    290637        0\n",
       "..   ...      ...       ...       ...      ...\n",
       "565  zpa      365      6381      6642        0\n",
       "566  zsl     2299     37803     37420        0\n",
       "567  zsm     1234      7898      8674        0\n",
       "568  zul  1066419  14324960  19162983        0\n",
       "569  zza      522      2384      2520        0\n",
       "\n",
       "[570 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('dataset-stats.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "merged=merged\n",
    "\n",
    "[[ -d $merged/tests ]] || mkdir -p $merged/tests\n",
    "[[ -f $merged/train.raw.tsv ]] || (\n",
    "    for i in datasets/*-eng; do\n",
    "        lang=$(echo $i | awk -F '[/-]' '{print $2}')\n",
    "        cp $i/tests/*.* $merged/tests 2> /dev/null\n",
    "        paste <(zcat $i/train.meta.gz) $i/train.$lang $i/train.eng  | sed \"s/^/$lang\\t/\" \n",
    "    done\n",
    ") >  $merged/train.raw.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw------- 1 tgowda G-819290 119G Jun  7 03:42 merged/train.raw.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh merged/train.raw.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 merged/train-sample.raw.tsv\n",
      "abk\tJW300-abk_eng\tАҵакы\tTable of Contents\n",
      "abk\tJW300-abk_eng\t© 2016 Watch Tower Bible and Tract Society of Pennsylvania\t© 2016 Watch Tower Bible and Tract Society of Pennsylvania\n"
     ]
    }
   ],
   "source": [
    "# smaleer file for development  with spark\n",
    "!head -100000 merged/train.raw.tsv > merged/train-sample.raw.tsv\n",
    "!wc -l merged/train-sample.raw.tsv\n",
    "!head -2 merged/train-sample.raw.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 's cool @-@ stuff ... ! http://isi.edu @id #hashtag email@gmail.com and , this but oh.no no ... no .\n",
      "मैं तुमसे प्यार करता हूँ ! । चिल्लाईए मत ।\n"
     ]
    }
   ],
   "source": [
    "from sacremoses import MosesTokenizer, MosesPunctNormalizer\n",
    "from html import unescape\n",
    "\n",
    "normr = MosesPunctNormalizer(\n",
    "        lang='en',\n",
    "        norm_quote_commas=True,\n",
    "        norm_numbers=True,\n",
    "        pre_replace_unicode_punct=True,\n",
    "        post_remove_control_chars=True,\n",
    "    )\n",
    "tok = MosesTokenizer(lang='en')\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    try:\n",
    "        text=unescape(text)\n",
    "        text = normr.normalize(text)\n",
    "        text = tok.tokenize(text, escape=False, return_str=True, aggressive_dash_splits=True,\n",
    "            protected_patterns=tok.WEB_PROTECTED_PATTERNS)\n",
    "        return text\n",
    "    except:\n",
    "        if text:\n",
    "            return '<TOKERR> ' + text\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "tokenize_src = tokenize_eng # using english ton source; not terrific, but not terrible either\n",
    "print(tokenize_eng(\"This's cool-stuff...! http://isi.edu  @id #hashtag email@gmail.com and,this but oh.no  no... no.\"))\n",
    "print(tokenize_src(\"मैं तुमसे प्यार करता हूँ!। चिल्लाईए मत।\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"SacreMoses Tokenizer on PySpark\") \\\n",
    "    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = 'merged/train.raw.tsv'\n",
    "df = spark.read.csv(raw_file, sep='\\t', schema='lang STRING, ds_name STRING, src STRING, eng STRING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok = df.rdd.map(lambda r: (r.lang, r.ds_name, tokenize_src(r.src), tokenize_eng(r.eng)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving at merged/train.tok.tsv\n"
     ]
    }
   ],
   "source": [
    "def to_tsv(rec):\n",
    "    return '\\t'.join(col.replace('\\t', ' ') for col in rec)\n",
    "\n",
    "out_file = raw_file.replace('.raw.tsv', '.tok.tsv')\n",
    "print(f'saving at {out_file}')\n",
    "df_tok.map(to_tsv).saveAsTextFile(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Select top languages; exclude extreme low resource languages\n",
    "\n",
    "Top is based on number of parallel sentences or tokens \n",
    "\n",
    "It would be nice to see what are top languages based on number of speakers. \n",
    "\n",
    "https://store.ethnologue.com/2019-ethnologue-200 has a list, but its $250 to obtain it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abk-eng\n",
      "ace-eng\n",
      "ach-eng\n",
      "acm-eng\n",
      "acu-eng\n",
      "ada-eng\n",
      "ady-eng\n",
      "aed-eng\n",
      "afb-eng\n",
      "afh-eng\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls datasets/ | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"xl/16.1.1\" with \"gcc/7.3.0\".\n",
      "\n",
      "\n",
      "Inactive Modules:\n",
      "  1) spectrum_mpi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module load gcc/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
