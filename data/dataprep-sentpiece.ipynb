{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from html import unescape\n",
    "import logging as log\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "log.basicConfig(level=log.INFO)\n",
    "SCHEMA = 'lang STRING, ds_name STRING, src STRING, eng STRING'\n",
    "\n",
    "def row_to_tsv(row):\n",
    "    return f'{row.lang}\\t{row.ds_name}\\t{row.src}\\t{row.eng}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c101-194.frontera.tacc.utexas.edu:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Raw data cleanup on PySpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2b29a51b2f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Raw data cleanup on PySpark\") \\\n",
    "    .config(\"spark.driver.memory\", \"120g\") \\\n",
    "    .getOrCreate()\n",
    "# I have a lot of mem, so 120g -- use all\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = 'merged/train.raw.tsv'\n",
    "raw_df = spark.read.csv(raw_file, sep='\\t', schema=SCHEMA)\\\n",
    "    .filter(\"ds_name != 'wiki_matrix_v1-tam_eng' and ds_name != 'wiki_matrix_v1-tel_eng'\")\n",
    "# there was an error processing wiki_matrix_v1; so exclude them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_file = 'merged/train.raw.dedup.tsv'\n",
    "raw_df.drop_duplicates(['src', 'eng'])\\\n",
    "    .rdd.map(row_to_tsv)\\\n",
    "    .saveAsTextFile(dedup_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude Test Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = []\n",
    "for eng in Path('merged/tests').glob(\"*.eng\"):\n",
    "    src_name = eng.name.replace(\".eng\", \"\").split(\"-\")[-1].split(\"_\")[0]\n",
    "    src = eng.with_suffix(\".\"+src_name)\n",
    "    assert src.exists()\n",
    "    tests.append((src, eng))\n",
    "    \n",
    "log.info(f\"Found {len(tests_tok)} held out sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# length ratios -- mean and std dev -- to spot od ones\n",
    "\n",
    "Length ratios are characters because we haven't tokenized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_char_lenghts(rec):\n",
    "    return (rec.lang, \n",
    "                (len(rec.src.strip()) if rec.src else 0,\n",
    "                len(rec.eng.strip()) if rec.eng else 0))\n",
    "def map_word_lenghts(rec):\n",
    "    return (rec.lang, \n",
    "                (len(rec.src.strip().split()) if rec.src else 0,\n",
    "                len(rec.eng.strip().split()) if rec.eng else 0))\n",
    "\n",
    "\n",
    "len_rdd = raw_df.rdd.map(map_word_lenghts).filter(lambda r: all(r[1]))\\\n",
    "    .persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    # try to keep it in memory if there is room, or spill it to disk when there isn't! cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oar', 0.7738), ('orm', 0.9523), ('twi', 1.1435), ('kik', 1.026), ('kaz', 0.954)]\n",
      "[('oar', 0.2412), ('orm', 0.2886), ('twi', 0.3254), ('kik', 0.3085), ('kaz', 0.4442)]\n"
     ]
    }
   ],
   "source": [
    "def key_count(rdd):\n",
    "    return (rdd.mapValues(lambda v: 1)\n",
    "        .reduceByKey(lambda a, b: a + b)\n",
    "        .collectAsMap())\n",
    "    \n",
    "def compute_key_mean(rdd, precision=4):\n",
    "    \"\"\"Compute mean per key\"\"\"\n",
    "    means = (rdd.mapValues(lambda v: (v, 1)) # (sum, count)\n",
    "        .reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1]))   # merge: (s1, c1) + (s2, c2)\n",
    "        .mapValues(lambda v: v[0]/v[1]) # mean=sum/count\n",
    "        .collectAsMap())\n",
    "    return {k: round(v, precision) for k, v in means.items()}\n",
    "\n",
    "len_ratio_rdd = len_rdd.map(lambda r: (r[0], r[1][0]/r[1][1]))  # lang, src_len/tgt_len\n",
    "len_ratio_mean = compute_key_mean(len_ratio_rdd)\n",
    "print(list(len_ratio_mean.items())[:5])\n",
    "\n",
    "def deviation(rec):\n",
    "    lang, ratio = rec\n",
    "    return lang, (len_ratio_mean[lang] - ratio)**2\n",
    "\n",
    "len_ratio_std_sq = compute_key_mean(len_ratio_rdd.map(deviation))\n",
    "len_ratio_std = {k: round(math.sqrt(v), 4) for k,v  in len_ratio_std_sq.items()}\n",
    "\n",
    "print(list(len_ratio_std.items())[:5])\n",
    "\n",
    "counts = key_count(len_ratio_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Wrote lang-word-len-stats-raw.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#len_stats_file = 'lang-char-len-stats.tsv'\n",
    "len_stats_file = 'lang-word-len-stats-raw.tsv'\n",
    "all_langs = set(len_ratio_std.keys()) | set(len_ratio_mean.keys())\n",
    "assert all_langs == set(len_ratio_std.keys())\n",
    "assert all_langs == set(len_ratio_mean.keys())\n",
    "all_langs = list(sorted(all_langs, key=counts.get, reverse=True))\n",
    "\n",
    "all_stats = []\n",
    "with open(len_stats_file, 'w') as wrt:\n",
    "    wrt.write(f\"Lang\\tMean\\tSTD\\tSentences\\n\")\n",
    "    for lang in all_langs:\n",
    "        mu = round(len_ratio_mean[lang], 4)\n",
    "        std = round(len_ratio_std[lang], 4)        \n",
    "        wrt.write(f\"{lang}\\t{mu}\\t{std}\\t{counts[lang]:,}\\n\")\n",
    "        all_stats.append((lang, mu, std, counts[lang]))\n",
    "log.info(f\"Wrote {len_stats_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in all_stats if x[-1] > 10_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fewer words: zho mean: 0.1856\n",
      "Fewer words: tha mean: 0.5345\n",
      "Fewer words: jpn mean: 0.1361\n",
      "Fewer words: mal mean: 0.6509\n",
      "Fewer words: mya mean: 0.6278\n",
      "Fewer words: kan mean: 0.5852\n",
      "Fewer words: kal mean: 0.6631\n",
      "Fewer words: cmn mean: 0.1765\n",
      "Fewer words: syr mean: 0.6349\n",
      "Fewer words: chr mean: 0.6648\n",
      "Fewer words: shi mean: 0.607\n",
      "Fewer words: tlh mean: 0.5933\n",
      "Fewer words: iku mean: 0.6186\n",
      "Many words: hrv mean: 1.622\n",
      "Many words: tah mean: 1.569\n",
      "Many words: ton mean: 1.686\n",
      "Many words: yap mean: 1.5157\n",
      "Many words: tvl mean: 1.5704\n",
      "Many words: hne mean: 1.6882\n",
      "Many words: jsl mean: 2.2187\n",
      "Many words: kvk mean: 1.5521\n",
      "Many words: ada mean: 1.5286\n",
      "Many words: ksw mean: 1.516\n",
      "Many words: lao mean: 1.8509\n",
      "Many words: csl mean: 1.7552\n",
      "Many words: quc mean: 1.582\n",
      "Many words: chq mean: 1.8047\n",
      "Many words: gbi mean: 1.7155\n",
      "Many words: ang mean: 1.7058\n",
      "Many words: tss mean: 1.8399\n",
      "Many words: kac mean: 1.5439\n",
      "High variance: nld std: 2.1228\n",
      "High variance: ell std: 2.2567\n",
      "High variance: slk std: 2.0236\n",
      "High variance: slv std: 2.0608\n",
      "High variance: pol std: 2.2317\n",
      "High variance: lit std: 2.013\n",
      "High variance: hun std: 2.1515\n",
      "High variance: mlt std: 2.1518\n",
      "High variance: hrv std: 3.1753\n",
      "High variance: tsn std: 2.2415\n",
      "High variance: sun std: 3.2385\n",
      "High variance: kbh std: 5.0453\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for lang, mu, std, _ in all_stats[:350]:\n",
    "    if mu < 2/3:\n",
    "        print('Fewer words:', lang, 'mean:',  mu)\n",
    "\n",
    "for lang, mu, std, _ in all_stats[:350]:        \n",
    "    if mu > 3/2:\n",
    "        print('Many words:', lang, 'mean:',  mu)\n",
    "\n",
    "for lang, mu, std, _ in all_stats[:350]:\n",
    "    if std > 2:\n",
    "        print('High variance:', lang, 'std:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MyFilter:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.min_len = 1\n",
    "        self.max_len = 120\n",
    "        self.len_ratio = 5\n",
    "        self.max_word_len = 30\n",
    "        self.remove_urls = True\n",
    "        #self.stats = stats \n",
    "\n",
    "    \n",
    "    def __call__(self, rec):\n",
    "        lang, provenance, src, eng = rec\n",
    "        if not src or not eng or not src.strip() or not eng.strip():\n",
    "            return 'EMPTY'\n",
    "        src, tgt = src.strip(), eng.strip()\n",
    "\n",
    "        if src == eng:\n",
    "            return 'COPY'\n",
    "\n",
    "        src_toks = src.split()\n",
    "        eng_toks = eng.split()\n",
    "        \n",
    "        if len(src_toks) < self.min_len or len(eng_toks) < self.min_len:\n",
    "            return 'MIN_LEN'\n",
    "\n",
    "        if len(src_toks) > self.max_len or len(eng_toks) > self.max_len:\n",
    "            return 'MAX_LEN'\n",
    "\n",
    "        if not (1/self.len_ratio <= len(src_toks)/len(eng_toks) <= self.len_ratio):\n",
    "            return 'LEN_RATIO'\n",
    "        \n",
    "        if any(len(t) > self.max_word_len for t in src_toks)\\\n",
    "            or any(len(t) > self.max_word_len for t in eng_toks):\n",
    "            return 'MAX_WORD_LEN'\n",
    "        \n",
    "        if 'http' in src or 'http' in eng:\n",
    "            return 'HTTP'\n",
    "        \n",
    "        return None # no reason to drop\n",
    "\n",
    "my_filter = MyFilter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO: \n",
    "\n",
    "- [ ] Xml unescapoe \n",
    "- [ ] drop URLs \n",
    "- [ ] drop abnormal lengths\n",
    "- [ ] drop empty \n",
    "- [ ] drop copy\n",
    "- [ ] drop if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
